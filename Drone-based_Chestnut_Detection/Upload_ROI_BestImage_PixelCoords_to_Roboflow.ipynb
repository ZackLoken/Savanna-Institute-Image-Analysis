{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Upload Best Image and Polygon Mask to Roboflow</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import exiftool\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ExifTool is accessible\n",
    "try:\n",
    "    subprocess.run([\"exiftool\", \"-ver\"], check=True)\n",
    "    print(\"ExifTool is accessible.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"ExifTool is not accessible.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory for IDP outputs\n",
    "dir = \"C:/Users/exx/EasyIDP/Route9_Orchard4/Outputs/\"\n",
    "\n",
    "# Path to folder containing raw UAV images\n",
    "raw_img_folder_path = \"D:/Savanna Institute Drone 2023/Route 9/Raw Images/Orchard 4/20230823_Route9-Orchard4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the folder names in \"C:\\Users\\zack\\Desktop\\easyIDP\\Route9_Orchard3\\best5_images\". Store the folder names in a list\n",
    "folder_path = dir + \"best5_images\"\n",
    "folder_names = os.listdir(folder_path)\n",
    "\n",
    "# remove non integer names from the list\n",
    "tree_ID = [int(name) for name in folder_names if name.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tree ID is the key and the image names are the values.\n",
    "idp_img_names = {}\n",
    "for i in range(len(tree_ID)):\n",
    "    idp_img_names[tree_ID[i]] = os.listdir(folder_path + \"/\" + folder_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to folders containing IDP outputs from reverse projection\n",
    "idp_img_path = {}\n",
    "for i in range(len(tree_ID)):\n",
    "    idp_img_path[tree_ID[i]] = [folder_path + \"/\" + folder_names[i] + \"/\" + idp_img_names[tree_ID[i]][j] for j in range(len(idp_img_names[tree_ID[i]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sharpness and contrast for each idp image. \n",
    "def sharpness_contrast(img_path):\n",
    "    # read image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Sharpness is the Laplacian of the image gradients.\n",
    "    sharpness = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    # Contrast is the standard deviation of the pixel values in greyscale (RMS contrast).\n",
    "    contrast = np.std(img)\n",
    "    return sharpness, contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the image names to match the raw UAV image names. \n",
    "uav_img_names = {}\n",
    "\n",
    "# Remove \"{treeID}_\" from the start of every image name. \n",
    "for key in idp_img_names.keys():\n",
    "    uav_img_names[key] = [name.split(\"_\", 1)[1] for name in idp_img_names[key]]\n",
    "\n",
    "# Remove rest of image name after \"_D\"\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_names[key] = [name.split(\"_at\", 1)[0] for name in uav_img_names[key]]\n",
    "\n",
    "# Add \".JPG\" to the end of each image name\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_names[key] = [name + \".JPG\" for name in uav_img_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store image names as full path. Image directory is raw_img_folder_path\n",
    "uav_img_path = {}\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_path[key] = [raw_img_folder_path + \"/\" + name for name in uav_img_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate gimbal pitch using exiftool. \n",
    "# Gimbal pitch is the angle of the camera from the horizontal plane.\n",
    "def gimbal_pitch(img_path):\n",
    "    with exiftool.ExifToolHelper() as et:\n",
    "        for d in et.get_tags(img_path, tags=[\"GimbalPitchDegree\"]):\n",
    "            return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sharpness and contrast for all cropped images (the outputs from easyIDP backward projection).\n",
    "sharpness_contrast_cropped = {}\n",
    "for key in idp_img_path.keys():\n",
    "    sharpness_contrast_cropped[key] = [sharpness_contrast(img) for img in idp_img_path[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gimbal pitch for all UAV images.\n",
    "gimbal_pitch_uav = {}\n",
    "for key in uav_img_path.keys():\n",
    "        gimbal_pitch_uav[key] = [gimbal_pitch(img) for img in uav_img_path[key]]\n",
    "        gimbal_pitch_uav[key] = [list(d.values())[1] for d in gimbal_pitch_uav[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritize gimbal pitch unless sharpness OR contrast highest value is more than 15% larger than \n",
    "# gimbal pitch == 90 (rounded) sharpness or contrast. If no gimbal pitch values are equal to 90 (rounded),\n",
    "# or contrast and sharpness are more than 15% larger than gimbal pitch == 90 (rounded), then the image \n",
    "# with the highest sharpness is selected. If sharpness values are within 15% of each other, then the \n",
    "# image with the highest contrast is selected.\n",
    "\n",
    "def best_img(uav_img_path, sharpness_contrast_cropped, gimbal_pitch_uav):\n",
    "    # store image paths, sharpnes, contrast, and gimbal pitch of every image containing treeID\n",
    "    img_data = []\n",
    "    for i in range(len(uav_img_path)):\n",
    "        img_data.append([uav_img_path[i], sharpness_contrast_cropped[i][0], sharpness_contrast_cropped[i][1], gimbal_pitch_uav[i]])\n",
    "    # convert img_data to a pandas dataframe\n",
    "    df = pd.DataFrame(img_data, columns=[\"img_path\", \"sharpness\", \"contrast\", \"gimbal_pitch\"])\n",
    "    \n",
    "    # Find the images with gimbal pitch == abs(90) when rounded to the nearest whole number\n",
    "    gimbal_pitch_90 = df.loc[df[\"gimbal_pitch\"].abs().round() == 90]\n",
    "\n",
    "    # if multiple images have gimbal pitch == abs(90), or if largest sharpness | contrast for tree \n",
    "    # is more than 15% larger than the largest sharpness/contrast value for gimbal pitch == 90,\n",
    "    # best image is the image with the highest sharpness. \n",
    "    if len(gimbal_pitch_90) == 0 or (df[\"sharpness\"].max() - gimbal_pitch_90[\"sharpness\"].max() > 0.15 * df[\"sharpness\"].max()) or (df[\"contrast\"].max() - gimbal_pitch_90[\"contrast\"].max() > 0.15 * df[\"contrast\"].max()):\n",
    "        best_image = df.loc[df[\"sharpness\"] == df[\"sharpness\"].max(), \"img_path\"].values[0]\n",
    "\n",
    "        # is the next highest sharpness value within 15% of the highest sharpness value?\n",
    "        if df[\"sharpness\"].max() - df[\"sharpness\"].nlargest(2).iloc[-1] <= 0.15 * df[\"sharpness\"].max():\n",
    "            \n",
    "            # if so, best image is the image with the highest contrast\n",
    "            max_contrast = df[\"contrast\"].max()\n",
    "            best_image = df.loc[df[\"contrast\"] == max_contrast, \"img_path\"].values[0]\n",
    "\n",
    "    # if not, best image is the image with the highest gimbal pitch == abs(90)\n",
    "    else:\n",
    "        best_image = gimbal_pitch_90.loc[gimbal_pitch_90[\"gimbal_pitch\"] == gimbal_pitch_90[\"gimbal_pitch\"], \"img_path\"].values[0]\n",
    "\n",
    "    return best_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tree ID, find the best UAV image\n",
    "best_images = {}\n",
    "for key in uav_img_path.keys():\n",
    "    best_images[key] = best_img(uav_img_path[key], sharpness_contrast_cropped[key], gimbal_pitch_uav[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pixel coordinates dictionary of best 5 images for each tree canopy from pkl file\n",
    "with open(dir + \"ROI_pixelCoords_best5.pkl\", \"rb\") as f:\n",
    "    pixelCoords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .JPG to end of image keys in pixel coords dictionary for each tree ID\n",
    "for key in pixelCoords.keys():\n",
    "    pixelCoords[key] = {k + \".JPG\": v for k, v in pixelCoords[key].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_images dict contains the file path of the best image for each tree ID. Use the file path to get the image name.\n",
    "best_image_names = {}\n",
    "for key in best_images.keys():\n",
    "    best_image_names[key] = best_images[key].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best image name to get corresponding pixel coordinates from pixelCoords dictionary\n",
    "best_image_pixelCoords = {}\n",
    "for key in best_image_names.keys():\n",
    "    best_image_pixelCoords[key] = pixelCoords[f'{key}'][best_image_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reshaping polygons \n",
    "def get_polygon(polygons):\n",
    "    polygons = np.array(polygons)\n",
    "    polygons = polygons.astype('float').reshape(-1, 2)\n",
    "    if polygons.shape[0] == 1 : return polygons\n",
    "    return np.squeeze(polygons)\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.imshow(image)\n",
    "    # ax.xaxis.tick_top()\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "# Function for plotting mask\n",
    "def plot_mask(ax, polygons):\n",
    "    ax.plot(polygons[:, 0], polygons[:, 1], c = 'y', linewidth = 0.7, alpha = 0.8)\n",
    "    return ax\n",
    "\n",
    "# function for plotting image with mask\n",
    "def plot_img_mask(image, polygon):\n",
    "    ax = img_show(image)\n",
    "    polygon = get_polygon(polygon)\n",
    "    plot_mask(ax, polygon)\n",
    "    return ax\n",
    "\n",
    "# modify get_bbox function to buffer the bounding box\n",
    "def get_buffered_bbox(image, polygon, buffer):\n",
    "    xmin = np.min(polygon[:, 0])\n",
    "    xmax = np.max(polygon[:, 0])\n",
    "    ymin = np.min(polygon[:, 1])\n",
    "    ymax = np.max(polygon[:, 1])\n",
    "    bbox = [max(0, xmin - buffer), max(0, ymin - buffer), min(xmax + buffer, image.size[0]), min(ymax + buffer, image.size[1])]\n",
    "    return bbox\n",
    "\n",
    "# Function to crop image using buffered bounding box\n",
    "def crop_image_bbox(image, bbox, buffer):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin = max(0, xmin - buffer)\n",
    "    ymin = max(0, ymin - buffer)\n",
    "    xmax = min(image.size[0], xmax + buffer)\n",
    "    ymax = min(image.size[1], ymax + buffer)\n",
    "    return image.crop((xmin, ymin, xmax, ymax))\n",
    "\n",
    "# modify polygon coords to reflect crop\n",
    "def crop_polygon(image, polygon, bbox, buffer):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin = max(0, xmin - buffer)\n",
    "    ymin = max(0, ymin - buffer)\n",
    "    xmax = min(image.size[0], xmax + buffer)\n",
    "    ymax = min(image.size[1], ymax + buffer)\n",
    "    polygon[:, 0] = np.clip(polygon[:, 0], xmin, xmax)\n",
    "    polygon[:, 1] = np.clip(polygon[:, 1], ymin, ymax)\n",
    "    polygon[:, 0] -= xmin\n",
    "    polygon[:, 1] -= ymin\n",
    "    return polygon\n",
    "\n",
    "# function to crop image using buffered bounding box\n",
    "def crop_image(image, polygon, buffer):\n",
    "    bbox = get_buffered_bbox(image, polygon, buffer)\n",
    "    cropped_image = crop_image_bbox(image, bbox, buffer)\n",
    "    cropped_polygon = crop_polygon(image, polygon, bbox, buffer)\n",
    "    return cropped_image, cropped_polygon\n",
    "\n",
    "\n",
    "# Calculate bbox in COCO format of cropped polygon\n",
    "def get_coco_bbox(polygon):\n",
    "    xmin = np.min(polygon[:, 0])\n",
    "    xmax = np.max(polygon[:, 0])\n",
    "    ymin = np.min(polygon[:, 1])\n",
    "    ymax = np.max(polygon[:, 1])\n",
    "    bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder in dir for storing raw UAV images in .PNG format. \n",
    "png_folder = dir + \"best_image_PNGs/\"\n",
    "if not os.path.exists(png_folder):\n",
    "    os.makedirs(png_folder)\n",
    "\n",
    "# create folder in dir for storing cropped images in .PNG format.\n",
    "cropped_png_folder = dir + \"Roboflow/images/\"\n",
    "if not os.path.exists(cropped_png_folder):\n",
    "    os.makedirs(cropped_png_folder)\n",
    "\n",
    "# create folder in dir for storing annotation JSON\n",
    "annotation_folder = dir + \"Roboflow/annotations/\"\n",
    "if not os.path.exists(annotation_folder):\n",
    "    os.makedirs(annotation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tree ID, crop the best image and save the cropped image with cropped polygon mask\n",
    "cropped_polygons = {}\n",
    "for key in best_image_pixelCoords.keys():\n",
    "    image = PIL.Image.open(best_images[key])\n",
    "    # copy the best image as png with transparent background and same dpi as original image in temp folder\n",
    "    image.save(png_folder + str(key) + \".png\", format = \"PNG\", dpi = (image.info[\"dpi\"][0], image.info[\"dpi\"][1]))\n",
    "    # load best image png\n",
    "    image = PIL.Image.open(png_folder + str(key) + \".png\")\n",
    "    polygon = best_image_pixelCoords[key]\n",
    "    buffer = int(200)\n",
    "    cropped_image, cropped_polygon = crop_image(image, polygon, buffer)\n",
    "    cropped_polygons[key] = cropped_polygon\n",
    "    # save cropped image as png with transparent background and same dpi as original image in cropped_png_folder\n",
    "    cropped_image.save(cropped_png_folder + str(key) + \".png\", format = \"PNG\", dpi = (image.info[\"dpi\"][0], image.info[\"dpi\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best image and corresponding cropped image polygon coordinates to a JSON file in COCO format. \n",
    "# COCO JSON file includes the following fields: \n",
    "\n",
    "# “info”: This field contains metadata about the dataset, such as the version, description, and contributor information\n",
    "\n",
    "# “licenses”: This field contains information about the licenses associated with the images and videos in the dataset\n",
    "\n",
    "# “images”: This field contains a list of dictionaries, each representing an image in the dataset. Each dictionary includes the following fields:\n",
    "#     “id”: The unique identifier for the image (i.e., key/treeID)\n",
    "#     “width”: The width of the image in pixels\n",
    "#     “height”: The height of the image in pixels\n",
    "#     “file_name”: The file name of the image\n",
    "#     “license”: The license associated with the image\n",
    "#     “date_captured”: The date the image was captured (optional)\n",
    "\n",
    "# “annotations”: This field contains a list of dictionaries, each representing an annotation for an image in the dataset. Each dictionary includes the following fields:\n",
    "#     “id”: The unique identifier for the annotation (i.e., key/treeID)\n",
    "#     “image_id”: The identifier for the image to which the annotation belongs\n",
    "#     “category_id”: The identifier for the category (i.e., class) to which the annotation belongs\n",
    "#     “bbox”: The bounding box for the annotation (i.e., bounding box of the canopy polygon in x,y,w,h format)\n",
    "#     “area”: The area of the bbox in square pixels (w * h)\n",
    "#     “segmentation”: The segmentation mask for the annotation (i.e., canopy polygon)\n",
    "#     “iscrowd”: A binary flag indicating whether the annotation represents a single object or a group of objects)\n",
    "#     “attributes”: Additional attributes associated with the annotation (optional)\n",
    "\n",
    "###-------------------------------------------------------------------------------------------------------------------------------------------------------------------------###\n",
    "\n",
    "# create the COCO JSON file\n",
    "coco_data = {}\n",
    "coco_data[\"info\"] = {\n",
    "    \"description\": \"Route 9 Orchard 4\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"contributor\": \"Zack Loken\",\n",
    "    \"date_created\": \"2024-07-04\"\n",
    "}\n",
    "\n",
    "coco_data[\"licenses\"] = [\n",
    "    {\n",
    "        \"url\": \"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en\",\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\"\n",
    "    }\n",
    "]\n",
    "\n",
    "coco_data[\"images\"] = []\n",
    "coco_data[\"annotations\"] = []\n",
    "\n",
    "# add cropped best_image data from cropped_png_folder + str(key) + \".png\") to coco_data[\"images\"]\n",
    "for key in best_images.keys():\n",
    "    image = PIL.Image.open(cropped_png_folder + str(key) + \".png\")\n",
    "    image_data = {\n",
    "        \"id\": key,\n",
    "        \"width\": image.size[0],\n",
    "        \"height\": image.size[1],\n",
    "        \"file_name\": str(key) + \".png\",\n",
    "        \"license\": 1,\n",
    "        \"date_captured\": \"08-23-2023\"\n",
    "    }\n",
    "    coco_data[\"images\"].append(image_data)\n",
    "\n",
    "# add cropped_polygon data from cropped_polygons[key] to coco_data[\"annotations\"]\n",
    "for key in cropped_polygons.keys():\n",
    "    cropped_polygon = cropped_polygons[key]\n",
    "    # Calculate bbox in COCO format of cropped polygon\n",
    "    bbox = get_coco_bbox(cropped_polygon)\n",
    "    area = bbox[2] * bbox[3]\n",
    "    annotation_data = {\n",
    "        # id is original uav image name\n",
    "        \"id\": uav_img_names[key][0],\n",
    "        \"image_id\": key,\n",
    "        \"category_id\": \"Canopy\",\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": area,\n",
    "        \"segmentation\": [cropped_polygon.flatten().tolist()],\n",
    "        \"iscrowd\": False,\n",
    "        \"attributes\": {}\n",
    "    }\n",
    "    coco_data[\"annotations\"].append(annotation_data)\n",
    "\n",
    "# save coco_data to a JSON file\n",
    "with open(annotation_folder + \"canopyMasks.coco.json\", \"w\") as f:\n",
    "    json.dump(coco_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upload best cropped images and corresponding canopy polygons to Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the images and annotations to Roboflow\n",
    "import glob\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# API Key for project workspace:\n",
    "api_key = \"5dM5PdVffGR3ONX8CeRu\"\n",
    "\n",
    "# Initialize Roboflow client\n",
    "rf = Roboflow(api_key=api_key)\n",
    "\n",
    "# Retrieve your current workspace and project name\n",
    "print(rf.workspace())\n",
    "\n",
    "# annotation file path\n",
    "annotation_path = annotation_folder + \"canopyMasks.coco.json\"\n",
    "\n",
    "project = rf.workspace('chestnut-detection').project('route-9-orchard-3')\n",
    "\n",
    "# # Upload images and annotations to Roboflow\n",
    "# image_glob = glob.glob(cropped_png_folder + '/*' + \".png\")\n",
    "# for image_path in image_glob:\n",
    "#     print(project.single_upload(image_path = image_path, \n",
    "#                          annotation_path = annotation_path,\n",
    "#                          num_retry_uploads = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve images and annotations for easyIDP forward projection to CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# API Key for project workspace:\n",
    "api_key = \"5dM5PdVffGR3ONX8CeRu\"\n",
    "\n",
    "# Initialize Roboflow client\n",
    "rf = Roboflow(api_key=api_key)\n",
    "\n",
    "# Retrieve your current workspace and project names\n",
    "workspace = rf.workspace('chestnut-detection')\n",
    "project = workspace.project('route-9-orchard-3')\n",
    "\n",
    "# Output directory for images and annotations\n",
    "out_dir = \"S:/Zack/Imagery/Chestnut/roboflow/route9_orchard3\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# List all images in the project using search_all\n",
    "records = []\n",
    "for page in project.search_all(\n",
    "    prompt=\"\",\n",
    "    like_image=\"\",\n",
    "    offset=0,\n",
    "    limit=100,\n",
    "    tag=\"\",\n",
    "    class_name=\"\",\n",
    "    in_dataset=False,  # Set to False to include images not in a dataset\n",
    "    batch=False,\n",
    "    batch_id=\"\",\n",
    "    fields=[\"id\", \"created\", \"name\", \"labels\"],\n",
    "):\n",
    "    records.extend(page)\n",
    "\n",
    "# Download images and annotations\n",
    "for record in records:\n",
    "    image_id = record[\"id\"]\n",
    "    try:\n",
    "        # Use the search method to get the image details\n",
    "        image_details = project.search(image_id)\n",
    "        if not image_details:\n",
    "            raise ValueError(f\"Image {image_id} not found.\")\n",
    "        \n",
    "        image = image_details[0]  # Assuming the first result is the correct image\n",
    "        \n",
    "        # Download the image using the URL\n",
    "        image_url = image['url']\n",
    "        image_response = requests.get(image_url)\n",
    "        image_path = os.path.join(out_dir, f\"{image['name']}.jpg\")\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(image_response.content)\n",
    "        \n",
    "        # Get the annotation file\n",
    "        annotation = image['labels']\n",
    "        \n",
    "        # Save the annotation file\n",
    "        annotation_path = os.path.join(out_dir, f\"{image['name']}.json\")\n",
    "        with open(annotation_path, \"w\") as f:\n",
    "            json.dump(annotation, f)\n",
    "        \n",
    "        print(f\"Downloaded image and annotation for {image_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image or annotation for {image_id}: {e}\")\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(project))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyidp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
